{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i3qiskTi-A5",
        "outputId": "3098606e-37df-4dc7-d7df-954c78ae99c5"
      },
      "outputs": [],
      "source": [
        "pip install procgen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnJ0P8Pc_ZLc"
      },
      "source": [
        "# Permet d'afficher un GIF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D33hSg14kRT7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from procgen import ProcgenEnv\n",
        "from procgen_wrappers import VecExtractDictObs, TransposeFrame, ScaledFloatFrame\n",
        "\n",
        "env = ProcgenEnv(\n",
        "        num_envs=1,\n",
        "        env_name=\"fruitbot\",\n",
        "        start_level=0,\n",
        "        num_levels=100,\n",
        "        distribution_mode='easy',\n",
        "    )\n",
        "\n",
        "env = VecExtractDictObs(env, \"rgb\")\n",
        "env = TransposeFrame(env)\n",
        "env = ScaledFloatFrame(env)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUSIjykfkRWD",
        "outputId": "18e0a084-8c7d-47b4-b97a-1fef1a2d6375"
      },
      "outputs": [],
      "source": [
        "from agent import Agent\n",
        "\n",
        "agent = Agent().cuda()\n",
        "agent.load_state_dict(torch.load('agent_weights.pth'))\n",
        "agent.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBqhlDlCkRcL",
        "outputId": "c410eae1-7af7-412f-f2d8-93b636979b54"
      },
      "outputs": [],
      "source": [
        "\n",
        "import imageio\n",
        "from IPython.display import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def obs_to_image(obs):\n",
        "  return (obs[0].transpose(1,2,0) * 255).astype(np.uint8)\n",
        "\n",
        "def display_trajectory(frames, name, fps=25):\n",
        "  imageio.mimwrite('./' + name,\n",
        "                [obs_to_image(frame) for i, frame in enumerate(frames)],\n",
        "                fps=fps)\n",
        "  #return(Image(open('tmp.gif','rb').read(), width=500, height=500))\n",
        "\n",
        "frames = []\n",
        "obs = env.reset()\n",
        "\n",
        "while True:\n",
        "    frames.append(obs)\n",
        "    obs = torch.FloatTensor(obs).to('cuda')\n",
        "    action = agent(obs).argmax(1).cpu().numpy()\n",
        "    obs, _, done ,_ = env.step(action)\n",
        "    img = env.render()\n",
        "    if done[0]:\n",
        "        break\n",
        "\n",
        "env.close()\n",
        "\n",
        "display_trajectory(frames, \"run.gif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBdBQweEyMW-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDAAG8GGnVTv"
      },
      "source": [
        "**Choisir et mettre en oeuvre 3 méthodes !**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sATXn_GiDqt"
      },
      "source": [
        "# Méthode 1 : Vanilla Gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Giz-GnociuDL"
      },
      "outputs": [],
      "source": [
        "def grad_to_image(grad):\n",
        "  return (grad * 255).astype(np.uint8)\n",
        "\n",
        "def obs_to_image(obs):\n",
        "  return (obs[0].transpose(1,2,0) * 255).astype(np.uint8)\n",
        "\n",
        "def display_trajectory_grad(frames, name, fps=25):\n",
        "  imageio.mimwrite('./' + name,\n",
        "                [grad_to_image(frame)[0] for i, frame in enumerate(frames)],\n",
        "                fps=fps)\n",
        "  #return(Image(open('grad.gif','rb').read(), width=500, height=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBVYaX1GiKZa"
      },
      "outputs": [],
      "source": [
        "\n",
        "obs = env.reset()\n",
        "frames_1 = []\n",
        "frames_vanilla_grad = []\n",
        "while True:\n",
        "    frames_1.append(obs)\n",
        "    img = torch.from_numpy(obs[0].astype(np.float32))\n",
        "    obs = torch.FloatTensor(obs).to('cuda')\n",
        "\n",
        "    img = img.unsqueeze(0).cuda()\n",
        "    img.requires_grad_()\n",
        "\n",
        "    output = agent(img)\n",
        "    output_idx = output.argmax()\n",
        "    output_max = output[0, output_idx]\n",
        "\n",
        "    output_max.backward()\n",
        "\n",
        "    saliency, _ = torch.max(img.grad.data.abs(), dim=1)\n",
        "    #saliency = saliency.squeeze(0)\n",
        "\n",
        "\n",
        "    frames_vanilla_grad.append(saliency.cpu().numpy())\n",
        "\n",
        "    action = agent(obs).argmax(1).cpu().numpy()\n",
        "    obs, _, done ,_ = env.step(action)\n",
        "\n",
        "    if done[0]:\n",
        "        break\n",
        "\n",
        "env.close()\n",
        "\n",
        "display_trajectory(frames_1, \"framesv1.gif\")\n",
        "display_trajectory_grad(frames_vanilla_grad, \"vanilla_grad.gif\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8zey-Ya0lez3",
        "outputId": "3c882779-e6fc-459e-aa7b-8db189e0188b"
      },
      "outputs": [],
      "source": [
        "# On affiche le gif\n",
        "\n",
        "from matplotlib.animation import FuncAnimation\n",
        "%matplotlib inline\n",
        "\n",
        "# Spécifiez les chemins des fichiers GIF\n",
        "chemin_fichier_gif1 = 'framesv1.gif'\n",
        "chemin_fichier_gif2 = 'vanilla_grad.gif'\n",
        "\n",
        "# Lire les GIF\n",
        "images_gif1 = imageio.mimread(chemin_fichier_gif1)\n",
        "images_gif2 = imageio.mimread(chemin_fichier_gif2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# Initialiser les images des sous-plots\n",
        "img1 = axs[0].imshow(images_gif1[0])\n",
        "img2 = axs[1].imshow(images_gif2[0])\n",
        "\n",
        "# Fonction d'animation\n",
        "def update(frame):\n",
        "    img1.set_array(images_gif1[frame])\n",
        "    img2.set_array(images_gif2[frame])\n",
        "    return img1, img2\n",
        "\n",
        "# Créer l'animation\n",
        "num_frames = min(len(images_gif1), len(images_gif2))\n",
        "animation = FuncAnimation(fig, update, frames=num_frames, interval=100, blit=True)\n",
        "\n",
        "# Afficher l'animation\n",
        "from IPython.display import HTML\n",
        "HTML(animation.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6rL8SN9ndRZ"
      },
      "source": [
        "# Méthode 2 : Smooth Gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOtR93dTAK_x"
      },
      "outputs": [],
      "source": [
        "def get_vanilla_grad(img, model):\n",
        "  img.retain_grad()\n",
        "  output = model(img)\n",
        "  output_idx = output.argmax()\n",
        "  output_max = output[0, output_idx]\n",
        "  output_max.backward()\n",
        "\n",
        "  return img.grad\n",
        "\n",
        "\n",
        "def grad_to_image(grad):\n",
        "  return (grad * 255).astype(np.uint8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "kloANQukTiwu",
        "outputId": "9d34c82b-4019-47c8-a973-697298436a1b"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "obs = env.reset()\n",
        "\n",
        "\n",
        "img = torch.from_numpy(obs[0].astype(np.float32))\n",
        "img.requires_grad_()\n",
        "obs = torch.FloatTensor(obs).to('cuda')\n",
        "\n",
        "img = img.to('cuda').unsqueeze(0)\n",
        "\n",
        "grad = get_vanilla_grad(img, agent)\n",
        "\n",
        "saliency, _ = torch.max(abs(grad), dim=1)\n",
        "saliency = saliency.squeeze(0)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(saliency.cpu(), cmap='hot')\n",
        "plt.axis('off')\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9yj41yoK6JC"
      },
      "outputs": [],
      "source": [
        "# On calcule\n",
        "\n",
        "obs = env.reset()\n",
        "frames_2 = []\n",
        "frames_smooth_grad = []\n",
        "while True:\n",
        "    frames_2.append(obs)\n",
        "    img = torch.from_numpy(obs[0].astype(np.float32))\n",
        "    img.requires_grad_()\n",
        "    obs = torch.FloatTensor(obs).to('cuda')\n",
        "\n",
        "    img = img.to('cuda').unsqueeze(0)\n",
        "\n",
        "    grad = get_vanilla_grad(img, agent)\n",
        "\n",
        "    saliency, _ = torch.max(abs(grad), dim=1)\n",
        "    #saliency = saliency.squeeze(0)\n",
        "\n",
        "\n",
        "    frames_smooth_grad.append(saliency.cpu().numpy())\n",
        "\n",
        "    action = agent(obs).argmax(1).cpu().numpy()\n",
        "    obs, _, done ,_ = env.step(action)\n",
        "\n",
        "    if done[0]:\n",
        "        break\n",
        "\n",
        "env.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7N8625XcXkR"
      },
      "outputs": [],
      "source": [
        "#On sauvegarde sous forme de gif\n",
        "\n",
        "display_trajectory(frames_2, \"framesv2.gif\")\n",
        "display_trajectory_grad(frames_smooth_grad, 'grad_smooth.gif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fLRXBq-CdDrY",
        "outputId": "f31eb333-a225-431d-bc7a-ea7673077bd8"
      },
      "outputs": [],
      "source": [
        "# On affiche le gif\n",
        "\n",
        "from matplotlib.animation import FuncAnimation\n",
        "%matplotlib inline\n",
        "\n",
        "# Spécifiez les chemins des fichiers GIF\n",
        "chemin_fichier_gif1 = 'framesv2.gif'\n",
        "chemin_fichier_gif2 = 'grad_smooth.gif'\n",
        "\n",
        "# Lire les GIF\n",
        "images_gif1 = imageio.mimread(chemin_fichier_gif1)\n",
        "images_gif2 = imageio.mimread(chemin_fichier_gif2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# Initialiser les images des sous-plots\n",
        "img1 = axs[0].imshow(images_gif1[0])\n",
        "img2 = axs[1].imshow(images_gif2[0])\n",
        "\n",
        "# Fonction d'animation\n",
        "def update(frame):\n",
        "    img1.set_array(images_gif1[frame])\n",
        "    img2.set_array(images_gif2[frame])\n",
        "    return img1, img2\n",
        "\n",
        "# Créer l'animation\n",
        "num_frames = min(len(images_gif1), len(images_gif2))\n",
        "animation = FuncAnimation(fig, update, frames=num_frames, interval=100, blit=True)\n",
        "\n",
        "# Afficher l'animation\n",
        "from IPython.display import HTML\n",
        "HTML(animation.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvE3UQimniog"
      },
      "source": [
        "# Méthode 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csGAOnfNnkQB",
        "outputId": "fecd7264-31d7-43e6-f10b-d2c0b4e87b26"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "\n",
        "\n",
        "means, stds = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
        "train_transform = transforms.Compose([\n",
        " transforms.Resize((224, 224)),\n",
        " transforms.ToTensor(),\n",
        " transforms.Normalize(means, stds),\n",
        " ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        " transforms.Resize((224, 224)),\n",
        " transforms.ToTensor(),\n",
        " transforms.Normalize(means, stds),\n",
        " ])\n",
        "\n",
        "inv_normalize = transforms.Normalize(\n",
        " mean= [-m/s for m, s in zip(means, stds)],\n",
        " std= [1/s for s in stds]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkLDOCtCnk2H",
        "outputId": "e77d15c2-ea4e-4bc9-c1da-001315e7bbc6"
      },
      "outputs": [],
      "source": [
        "\n",
        "class HookFeatures():\n",
        "  def __init__(self, module):\n",
        "    self.feature_hook = module.register_forward_hook(self.feature_hook_fn)\n",
        "  def feature_hook_fn(self, module, input, output):\n",
        "    self.features = output.clone().detach()\n",
        "    self.gradient_hook = output.register_hook(self.gradient_hook_fn)\n",
        "  def gradient_hook_fn(self, grad):\n",
        "    self.gradients = grad\n",
        "  def close(self):\n",
        "    self.feature_hook.remove()\n",
        "    self.gradient_hook.remove()\n",
        "\n",
        "hook = HookFeatures(agent.features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTQQ-7r7sJ2s"
      },
      "outputs": [],
      "source": [
        "done = False\n",
        "obs = env.reset()\n",
        "\n",
        "frames_3 = []\n",
        "frames_hook = []\n",
        "\n",
        "while not done :\n",
        "  frames_3.append(obs) # Verifier que c'est au bon endroit\n",
        "  obs = torch.tensor(obs,requires_grad=True).to('cuda').float()\n",
        "  output = agent(obs)\n",
        "  output_idx = output.argmax()\n",
        "  output_max = output[0, output_idx]\n",
        "  output_max.backward()\n",
        "  action = output.argmax(dim=1)\n",
        "\n",
        "\n",
        "  gradients = hook.gradients\n",
        "  activations = hook.features\n",
        "  pooled_gradients = torch.mean(gradients, dim=[0, 2, 3]) # we take the average gradient of every chanels\n",
        "\n",
        "  for i in range(activations.shape[1]):\n",
        "      activations[:, i, :, :] *= pooled_gradients[i] # we multiply every chanels of the feature map with their corresponding averaged gradients\n",
        "\n",
        "  obs, _, done ,_ = env.step(action.cpu().numpy())\n",
        "\n",
        "\n",
        "  heatmap = torch.mean(activations, dim=1).squeeze()\n",
        "  heatmap = np.maximum(heatmap.detach().cpu(), 0)\n",
        "  heatmap /= torch.max(heatmap)\n",
        "  heatmap = cv2.resize(np.float32(heatmap), (obs.shape[2], obs.shape[3]))\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_RAINBOW) / 255\n",
        "  superposed_img = (heatmap) * 0.4 + obs[0].transpose(1, 2, 0)\n",
        "  result = np.clip(superposed_img,0,1)\n",
        "  frames_hook.append(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD00bv5nseyD",
        "outputId": "68b1db30-4b20-4e3a-8d4e-0ca67c8d4950"
      },
      "outputs": [],
      "source": [
        "#On affiche et sauvegarde sous forme de gif\n",
        "from PIL import Image as im\n",
        "\n",
        "def nparray_to_image(obs):\n",
        "  return (obs * 255).astype(np.uint8)\n",
        "\n",
        "def display_trajectory_hook(frames, name, fps=25):\n",
        "\n",
        "  imageio.mimwrite('./' + name,\n",
        "                [nparray_to_image(frame) for i, frame in enumerate(frames)],\n",
        "                fps=fps)\n",
        "\n",
        "\n",
        "display_trajectory(frames_3, \"framesv3.gif\")\n",
        "display_trajectory_hook(frames_hook, 'hook.gif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "_zZThlsyvGz5",
        "outputId": "00764c08-95b0-41b0-b0dd-c4763aecc473"
      },
      "outputs": [],
      "source": [
        "chemin_fichier_gif1 = 'hook.gif'\n",
        "images_gif1 = imageio.mimread(chemin_fichier_gif1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sXI93o6Ytxh-",
        "outputId": "98032982-330a-45c3-8dfa-2ee9aef801ee"
      },
      "outputs": [],
      "source": [
        "# On affiche le gif\n",
        "\n",
        "from matplotlib.animation import FuncAnimation\n",
        "%matplotlib inline\n",
        "\n",
        "# Spécifiez les chemins des fichiers GIF\n",
        "chemin_fichier_gif1 = 'framesv3.gif'\n",
        "chemin_fichier_gif2 = 'hook.gif'\n",
        "\n",
        "# Lire les GIF\n",
        "images_gif1 = imageio.mimread(chemin_fichier_gif1)\n",
        "images_gif2 = imageio.mimread(chemin_fichier_gif2)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# Initialiser les images des sous-plots\n",
        "img1 = axs[0].imshow(images_gif1[0])\n",
        "img2 = axs[1].imshow(images_gif2[0])\n",
        "\n",
        "# Fonction d'animation\n",
        "def update(frame):\n",
        "    img1.set_array(images_gif1[frame])\n",
        "    img2.set_array(images_gif2[frame])\n",
        "    return img1, img2\n",
        "\n",
        "# Créer l'animation\n",
        "num_frames = min(len(images_gif1), len(images_gif2))\n",
        "animation = FuncAnimation(fig, update, frames=num_frames, interval=100, blit=True)\n",
        "\n",
        "# Afficher l'animation\n",
        "from IPython.display import HTML\n",
        "HTML(animation.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c021TbOuJlh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
